{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all runs\n",
    "import os\n",
    "gp = '/home/kloudvoj/devel/prompt_optimization/runs/'\n",
    "runs = os.listdir(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter runs based on model and dataset\n",
    "import json\n",
    "def parse_field(ident, field):\n",
    "    with open(gp + ident + '/run_args.json', 'r') as f:\n",
    "        return json.load(f)[field]\n",
    "# filter runs by model\n",
    "models = [\n",
    "    \"gpt-4o-mini\", # 0\n",
    "    \"microsoft/Phi-3.5-mini-instruct\", # 1\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\", # 2\n",
    "    \"CohereForAI/aya-expanse-8b\", # 3\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\", # 4\n",
    "    \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\" # 5\n",
    "] \n",
    "\n",
    "by_model = lambda run_list, model: list(filter(lambda fd: parse_field(fd, 'model') == model, run_list))\n",
    "datasets = [ \n",
    "    \"openai/gsm8k\", # 0\n",
    "    \"microsoft/orca-math-word-problems-200k\", # 1\n",
    "    \"maveriq/bigbenchhard/snarks\", # 2\n",
    "    \"maveriq/bigbenchhard/navigate\", # 3\n",
    "    \"GBaker/MedQA-USMLE-4-options\", # 4\n",
    "    \"cais/mmlu/college_physics\", # 5\n",
    "]\n",
    "\n",
    "by_ds = lambda run_list, ds: list(filter(lambda fd: parse_field(fd, 'ds') == ds, run_list))\n",
    "by_min_iters = lambda run_list, iters: list(filter(lambda fd: parse_field(fd, 'max_iters') >= iters, run_list))\n",
    "by_min_pop = lambda run_list, pop: list(filter(lambda fd: parse_field(fd, 'initial_population_size') >= pop, run_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_args(ident, args): \n",
    "    with open(gp + ident + '/run_args.json', 'r') as f:\n",
    "        a = json.load(f)\n",
    "    for key in args: \n",
    "        value = a[key]\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison functions\n",
    "from tabulate import tabulate\n",
    "def compare_runs(idents, args):\n",
    "    table = []\n",
    "    for arg in args:\n",
    "        if type(arg) != list:\n",
    "            arg = [arg]\n",
    "        table.append(['/'.join(arg)])\n",
    "        for ident in idents:\n",
    "            with open(gp + ident + '/run_args.json', 'r') as f:\n",
    "                j = json.load(f) \n",
    "                table[-1].append('/'.join(str(j.get(a)) for a in arg))\n",
    "    headers = [\"RUN NUMBER\", *idents]\n",
    "    print(tabulate(table, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "            \n",
    "from IPython.display import SVG, display_html\n",
    "\n",
    "# Function to create an HTML div to display images side by side\n",
    "def display_side_by_side_svgs(*filenames):\n",
    "    svg_divs = ''.join([f'<div style=\"display:inline-block; margin:10px;\">{SVG(filename).data}</div>' for filename in filenames])\n",
    "    display_html(svg_divs, raw=True)\n",
    "\n",
    "def compare_plots(idents, plot_names):\n",
    "    for p in plot_names:\n",
    "        paths = [gp+i+'/plots/'+p+'.svg' for i in idents]\n",
    "        display_side_by_side_svgs(*paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════════════════════════════════╤══════════════════════════════════════╤══════════════════════════════════════╕\n",
      "│ RUN NUMBER                               │ 9214463                              │ 9214462                              │\n",
      "╞══════════════════════════════════════════╪══════════════════════════════════════╪══════════════════════════════════════╡\n",
      "│ model                                    │ mistralai/Mistral-Nemo-Instruct-2407 │ mistralai/Mistral-Nemo-Instruct-2407 │\n",
      "├──────────────────────────────────────────┼──────────────────────────────────────┼──────────────────────────────────────┤\n",
      "│ ds                                       │ cais/mmlu/college_physics            │ cais/mmlu/college_physics            │\n",
      "├──────────────────────────────────────────┼──────────────────────────────────────┼──────────────────────────────────────┤\n",
      "│ initial_population_size/mating_pool_size │ 30/20                                │ 30/20                                │\n",
      "├──────────────────────────────────────────┼──────────────────────────────────────┼──────────────────────────────────────┤\n",
      "│ max_iters/train_batch_size               │ 20/5                                 │ 20/5                                 │\n",
      "├──────────────────────────────────────────┼──────────────────────────────────────┼──────────────────────────────────────┤\n",
      "│ temp/sol_temp                            │ 0.5/0.25                             │ 0.5/0.25                             │\n",
      "├──────────────────────────────────────────┼──────────────────────────────────────┼──────────────────────────────────────┤\n",
      "│ filter_similar_method/filter_th          │ bert/0.95                            │ bert/0.95                            │\n",
      "├──────────────────────────────────────────┼──────────────────────────────────────┼──────────────────────────────────────┤\n",
      "│ points_range/sentences_per_point_range   │ [3, 6]/[1, 3]                        │ [3, 6]/[1, 3]                        │\n",
      "├──────────────────────────────────────────┼──────────────────────────────────────┼──────────────────────────────────────┤\n",
      "│ metapersonas/metastyles                  │ True/True                            │ False/False                          │\n",
      "╘══════════════════════════════════════════╧══════════════════════════════════════╧══════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Filter runs and compare their params and plots\n",
    "a = by_model(runs, models[4])\n",
    "a = by_ds(a, datasets[5])\n",
    "a = by_min_pop(a, 10)\n",
    "params = [\"model\", \"ds\", [\"initial_population_size\", \"mating_pool_size\"], [\"max_iters\",\"train_batch_size\"],[\"temp\", \"sol_temp\"], [\"filter_similar_method\",\"filter_th\"], [\"points_range\", \"sentences_per_point_range\"],[\"metapersonas\", \"metastyles\"]]\n",
    "plots = [\"steps\", \"average_semantic_similarity\"]\n",
    "compare_runs(a, params)\n",
    "#compare_plots(a, plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sep_results(ident):\n",
    "    out = {\"prompt\": [], \"usage\": [], \"score\": []}\n",
    "    with open(gp+ident+'/results.ndjson', 'r') as f:\n",
    "        for l in f.readlines()[1:]:\n",
    "            loaded_obj = json.loads(l)\n",
    "            obj_type = loaded_obj.pop('type')\n",
    "            out[obj_type].append(loaded_obj)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best in step 10 with avg fitness 0.8:\n",
      " \"First off, figure out what kind of question you're dealing with - it's either a multiple-choice science one, a simple math problem, or a physics riddle about forces and motion. Next up, grasp the crucial info in the question, like the type of radiation, electron levels, or forces at play. Lastly, apply the right science rule or formula to solve it, or use the elimination method for multiple-choice questions.\"\n",
      "Best in step 10 with avg fitness 0.6:\n",
      " 1. **Identify the main topic**: Focus on the key scientific concept or principle being tested in the question.\n",
      "2. **Analyze the question**: Break down the question to understand what's being asked and what information is relevant.\n",
      "3. **Apply relevant formulas/principles**: Recall and apply appropriate formulas, principles, or theories from physics, chemistry, or other sciences.\n",
      "4. **Calculate/derive the answer**: Perform any necessary calculations or logical deductions to find the answer.\n",
      "5. **Match with options**: Compare your calculated/derived value with the given options (A, B, C, D).\n",
      "6. **Select the correct answer**: Choose the option that matches your calculated/derived value.\n"
     ]
    }
   ],
   "source": [
    "def compare_best_in_gen(gen, idents):\n",
    "    for ident in idents:\n",
    "        results = load_sep_results(ident)\n",
    "        prompts = results['prompt']\n",
    "        g = prompts[(gen-1)*20:gen*20]\n",
    "\n",
    "        best = sorted(g, key = lambda x: x['avg_fitness'], reverse=True)\n",
    "        print(f\"Best in step {gen} with avg fitness {best[0]['avg_fitness']}:\\n {best[0]['traits'][0][0]}\")\n",
    "\n",
    "compare_best_in_gen(10, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
